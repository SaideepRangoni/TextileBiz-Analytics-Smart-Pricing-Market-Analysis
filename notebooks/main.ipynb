{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Cleaned dataset saved as 'Enhanced_Textile_Dataset.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Competitor Prices:   1%|‚ñè         | 7/493 [01:31<1:52:24, 13.88s/it]"
     ]
    }
   ],
   "source": [
    "# üìå Import necessary libraries\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "from fake_useragent import UserAgent\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# -------------------- CONFIG --------------------\n",
    "RAW_FILE = \"Textile_data2.txt.csv\"\n",
    "CLEANED_FILE = \"Enhanced_Textile_Dataset.csv\"\n",
    "PRICING_ANALYSIS_FILE = \"Pricing_Analysis_Report.csv\"\n",
    "OPTIMIZED_PRICING_FILE = \"Optimized_Pricing_Dataset.csv\"\n",
    "FINAL_ML_PREDICTION_FILE = \"Final_ML_Pricing_Dataset.csv\"\n",
    "MODEL_FILE = \"trained_model.pkl\"\n",
    "\n",
    "# ‚úÖ Load dataset\n",
    "if not os.path.exists(RAW_FILE):\n",
    "    raise FileNotFoundError(f\"‚ùå File '{RAW_FILE}' not found!\")\n",
    "\n",
    "df = pd.read_csv(RAW_FILE)\n",
    "\n",
    "# ‚úÖ Normalize column names\n",
    "df.columns = df.columns.str.strip().str.lower()\n",
    "\n",
    "# ‚úÖ Check for missing columns\n",
    "required_columns = [\"item\", \"cost price\", \"sale price\", \"mrp\", \"quality\", \"availability\", \"season\", \"location\"]\n",
    "missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "if missing_columns:\n",
    "    raise KeyError(f\"‚ùå Missing columns: {missing_columns}\")\n",
    "\n",
    "# ‚úÖ Remove missing values\n",
    "df = df.dropna(subset=[\"item\", \"sale price\"])\n",
    "\n",
    "# ‚úÖ Save cleaned dataset\n",
    "df.to_csv(CLEANED_FILE, index=False)\n",
    "print(f\"‚úÖ Cleaned dataset saved as '{CLEANED_FILE}'\")\n",
    "\n",
    "# -------------------- 1Ô∏è‚É£ PRICE SCRAPING (Amazon & Google) --------------------\n",
    "\n",
    "def get_headers():\n",
    "    ua = UserAgent()\n",
    "    return {\"User-Agent\": ua.random}\n",
    "\n",
    "PROXY_LIST = [\n",
    "    \"http://45.77.67.81:8080\", \"http://188.166.16.94:8118\",\n",
    "    \"http://165.227.199.59:3128\", \"http://178.62.193.19:8118\"\n",
    "]\n",
    "\n",
    "def get_random_proxy():\n",
    "    return {\"http\": random.choice(PROXY_LIST)}\n",
    "\n",
    "def get_amazon_price(product_name):\n",
    "    \"\"\"Scrapes Amazon price\"\"\"\n",
    "    try:\n",
    "        url = f\"https://www.amazon.in/s?k={product_name.replace(' ', '+')}\"\n",
    "        headers, proxy = get_headers(), get_random_proxy()\n",
    "        response = requests.get(url, headers=headers, proxies=proxy, timeout=15)\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        price_element = soup.select_one(\"span.a-price-whole\")\n",
    "        return int(price_element.text.replace(\",\", \"\")) if price_element else None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def get_google_price(product_name):\n",
    "    \"\"\"Scrapes Google for Amazon prices\"\"\"\n",
    "    try:\n",
    "        search_url = f\"https://www.google.com/search?q={product_name.replace(' ', '+')}+price+site:amazon.in\"\n",
    "        headers = get_headers()\n",
    "        response = requests.get(search_url, headers=headers, timeout=10)\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        price_element = soup.find(\"div\", class_=\"BNeawe iBp4i AP7Wnd\")\n",
    "        return int(price_element.text.replace(\"‚Çπ\", \"\").replace(\",\", \"\")) if price_element else None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# ‚úÖ Run price scraping with delays\n",
    "def get_price_with_delay(row):\n",
    "    time.sleep(random.uniform(5, 15))  # Random delay to avoid detection\n",
    "    return get_amazon_price(row[\"item\"]) or get_google_price(row[\"item\"]) or max(row[\"sale price\"] - 30, 0)\n",
    "\n",
    "# ‚úÖ Enable progress tracking\n",
    "tqdm.pandas(desc=\"Fetching Competitor Prices\")\n",
    "df[\"competitor price\"] = df.progress_apply(get_price_with_delay, axis=1)\n",
    "\n",
    "# ‚úÖ Save updated dataset\n",
    "df.to_csv(CLEANED_FILE, index=False)\n",
    "print(f\"‚úÖ Competitor prices added and saved as '{CLEANED_FILE}'\")\n",
    "\n",
    "# -------------------- 2Ô∏è‚É£ PRICING ANALYSIS --------------------\n",
    "\n",
    "# ‚úÖ Compute Price Differences\n",
    "df[\"price_difference\"] = df[\"sale price\"] - df[\"competitor price\"]\n",
    "\n",
    "# ‚úÖ Classify Items Based on Pricing\n",
    "def classify_price_status(row):\n",
    "    if row[\"price_difference\"] > 30:\n",
    "        return \"Overpriced\"\n",
    "    elif row[\"price_difference\"] < -30:\n",
    "        return \"Underpriced\"\n",
    "    else:\n",
    "        return \"Competitive\"\n",
    "\n",
    "df[\"price_status\"] = df.apply(classify_price_status, axis=1)\n",
    "\n",
    "# ‚úÖ Save Analysis Report\n",
    "df.to_csv(PRICING_ANALYSIS_FILE, index=False)\n",
    "print(f\"‚úÖ Pricing Analysis Report saved as {PRICING_ANALYSIS_FILE}\")\n",
    "\n",
    "# -------------------- 3Ô∏è‚É£ PRICE OPTIMIZATION --------------------\n",
    "\n",
    "# ‚úÖ Define Pricing Rules\n",
    "def adjust_price(row):\n",
    "    sale_price = row[\"sale price\"]\n",
    "    competitor_price = row[\"competitor price\"]\n",
    "    cost_price = row[\"cost price\"]\n",
    "\n",
    "    if pd.isna(competitor_price) or competitor_price <= 0:\n",
    "        return sale_price  # No competitor price, keep original\n",
    "\n",
    "    price_gap = sale_price - competitor_price\n",
    "    min_profit_margin = cost_price * 1.2  # Ensure 20% profit\n",
    "\n",
    "    if price_gap > 30:\n",
    "        return max(competitor_price + 10, min_profit_margin)  # Reduce price\n",
    "    elif price_gap < -30:\n",
    "        return min(competitor_price - 10, sale_price * 1.1)  # Increase price\n",
    "    else:\n",
    "        return sale_price  # Keep same\n",
    "\n",
    "df[\"optimized price\"] = df.apply(adjust_price, axis=1)\n",
    "\n",
    "# ‚úÖ Save Optimized Pricing Dataset\n",
    "df.to_csv(OPTIMIZED_PRICING_FILE, index=False)\n",
    "print(f\"‚úÖ Optimized pricing dataset saved as {OPTIMIZED_PRICING_FILE}\")\n",
    "\n",
    "# -------------------- 4Ô∏è‚É£ MACHINE LEARNING PRICE PREDICTION --------------------\n",
    "\n",
    "# ‚úÖ Load optimized dataset\n",
    "df = pd.read_csv(OPTIMIZED_PRICING_FILE)\n",
    "\n",
    "# ‚úÖ Generate \"total_sales\" based on season & item type\n",
    "def generate_seasonal_sales(row):\n",
    "    base_sales = np.random.randint(50, 150)\n",
    "    if \"cotton\" in row[\"item\"].lower() and \"summer\" in row[\"season\"].lower():\n",
    "        return np.random.randint(200, 500)\n",
    "    elif \"sweater\" in row[\"item\"].lower() and \"winter\" in row[\"season\"].lower():\n",
    "        return np.random.randint(250, 600)\n",
    "    else:\n",
    "        return base_sales\n",
    "\n",
    "df[\"total_sales\"] = df.apply(generate_seasonal_sales, axis=1)\n",
    "\n",
    "# ‚úÖ Select Features & Target Variable\n",
    "features = [\"cost price\", \"sale price\", \"competitor price\", \"total_sales\"]\n",
    "target = \"optimized price\"\n",
    "\n",
    "# ‚úÖ Drop rows with missing values\n",
    "df = df.dropna(subset=features + [target])\n",
    "\n",
    "# ‚úÖ Train-Test Split\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ‚úÖ Train Model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# ‚úÖ Save Model\n",
    "with open(MODEL_FILE, \"wb\") as file:\n",
    "    pickle.dump(model, file)\n",
    "\n",
    "print(f\"‚úÖ Model saved successfully as {MODEL_FILE}!\")\n",
    "\n",
    "# ‚úÖ Save final dataset\n",
    "df.to_csv(FINAL_ML_PREDICTION_FILE, index=False)\n",
    "print(f\"‚úÖ ML-Predicted pricing dataset saved as {FINAL_ML_PREDICTION_FILE}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
